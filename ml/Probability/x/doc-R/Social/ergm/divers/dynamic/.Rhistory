# Read the Data
data = read.csv("res/cereals.csv", header=T)
# Random sampling
samplesize = 0.60 * nrow(data)
set.seed(80)
index = sample( seq_len ( nrow ( data ) ), size = samplesize )
# Create training and test set
datatrain = data[ index, ]
datatest = data[ -index, ]
max = apply(data , 2 , max)
min = apply(data, 2 , min)
scaled = as.data.frame(scale(data, center = min, scale = max - min))
# load library
library(neuralnet)
# creating training and test set
trainNN = scaled[index , ]
testNN = scaled[-index , ]
# fit neural network
set.seed(2)
NN = neuralnet(rating ~ calories + protein + fat + sodium + fiber, trainNN, hidden = 3 , linear.output = T )
# plot neural network
plot(NN)
predict_testNN = compute(NN, testNN[,c(1:5)])
predict_testNN = (predict_testNN$net.result * (max(data$rating) - min(data$rating))) + min(data$rating)
plot(datatest$rating, predict_testNN, col='blue', pch=16, ylab = "predicted rating NN", xlab = "real rating")
abline(0,1)
install.packages("neuralnet")
# load library
library(neuralnet)
# creating training and test set
trainNN = scaled[index , ]
testNN = scaled[-index , ]
# fit neural network
set.seed(2)
NN = neuralnet(rating ~ calories + protein + fat + sodium + fiber, trainNN, hidden = 3 , linear.output = T )
# plot neural network
plot(NN)
predict_testNN = compute(NN, testNN[,c(1:5)])
predict_testNN = (predict_testNN$net.result * (max(data$rating) - min(data$rating))) + min(data$rating)
plot(datatest$rating, predict_testNN, col='blue', pch=16, ylab = "predicted rating NN", xlab = "real rating")
abline(0,1)
# Calculate Root Mean Square Error (RMSE)
RMSE.NN = (sum((datatest$rating - predict_testNN)^2) / nrow(datatest)) ^ 0.5
# Load libraries
library(boot)
library(plyr)
# Initialize variables
set.seed(50)
k = 100
RMSE.NN = NULL
List = list( )
# Fit neural network model within nested for loop
for(j in 10:65){
for (i in 1:k) {
index = sample(1:nrow(data),j )
trainNN = scaled[index,]
testNN = scaled[-index,]
datatest = data[-index,]
NN = neuralnet(rating ~ calories + protein + fat + sodium + fiber, trainNN, hidden = 3, linear.output= T)
predict_testNN = compute(NN,testNN[,c(1:5)])
predict_testNN = (predict_testNN$net.result*(max(data$rating)-min(data$rating)))+min(data$rating)
RMSE.NN [i]<- (sum((datatest$rating - predict_testNN)^2)/nrow(datatest))^0.5
}
List[[j]] = RMSE.NN
}
Matrix.RMSE = do.call(cbind, List)
## Prepare boxplot
boxplot(Matrix.RMSE[,56], ylab = "RMSE", main = "RMSE BoxPlot (length of traning set = 65)")
## Variation of median RMSE
#install.packages("matrixStats")
library(matrixStats)
med = colMedians(Matrix.RMSE)
X = seq(10,65)
plot (med~X, type = "l", xlab = "length of training set", ylab = "median RMSE", main = "Variation of RMSE with length of training set")
install.packages("matrixStats")
install.packages("lattice")
install.packages("Hmisc")
install.packages("nortest")
install.packages("lawstat")
install.packages("car")
install.packages("gap")
install.packages("outliers")
install.packages("mclust")
install.packages("mclust")
install.packages("nlme")
install.packages("faraway")
install.packages("varcompci")
## Variation of median RMSE
#install.packages("matrixStats")
library(matrixStats)
med = colMedians(Matrix.RMSE)
X = seq(10,65)
plot (med~X, type = "l", xlab = "length of training set", ylab = "median RMSE", main = "Variation of RMSE with length of training set")
## Read data.
y <- scan("../res/contact.dat",skip=25)
## Read data.
y <- scan("res/contact.dat",skip=25)
## Read data.
y <- scan("/home/aghiles/aghiles/code/R/Handbook/res/contact.dat",skip=25)
# Read the Data
data = read.csv("/home/aghiles/aghiles/code/R/Handbook/res/cereals.csv", header=T)
# Random sampling
samplesize = 0.60 * nrow(data)
set.seed(80)
index = sample( seq_len ( nrow ( data ) ), size = samplesize )
# Create training and test set
datatrain = data[ index, ]
datatest = data[ -index, ]
max = apply(data , 2 , max)
min = apply(data, 2 , min)
scaled = as.data.frame(scale(data, center = min, scale = max - min))
# load library
library(neuralnet)
# creating training and test set
trainNN = scaled[index , ]
testNN = scaled[-index , ]
# fit neural network
set.seed(2)
NN = neuralnet(rating ~ calories + protein + fat + sodium + fiber, trainNN, hidden = 3 , linear.output = T )
# plot neural network
plot(NN)
predict_testNN = compute(NN, testNN[,c(1:5)])
predict_testNN = (predict_testNN$net.result * (max(data$rating) - min(data$rating))) + min(data$rating)
plot(datatest$rating, predict_testNN, col='blue', pch=16, ylab = "predicted rating NN", xlab = "real rating")
abline(0,1)
# Calculate Root Mean Square Error (RMSE)
RMSE.NN = (sum((datatest$rating - predict_testNN)^2) / nrow(datatest)) ^ 0.5
# Load libraries
library(boot)
library(plyr)
# Initialize variables
set.seed(50)
k = 100
RMSE.NN = NULL
List = list( )
# Fit neural network model within nested for loop
for(j in 10:65){
for (i in 1:k) {
index = sample(1:nrow(data),j )
trainNN = scaled[index,]
testNN = scaled[-index,]
datatest = data[-index,]
NN = neuralnet(rating ~ calories + protein + fat + sodium + fiber, trainNN, hidden = 3, linear.output= T)
predict_testNN = compute(NN,testNN[,c(1:5)])
predict_testNN = (predict_testNN$net.result*(max(data$rating)-min(data$rating)))+min(data$rating)
RMSE.NN [i]<- (sum((datatest$rating - predict_testNN)^2)/nrow(datatest))^0.5
}
List[[j]] = RMSE.NN
}
Matrix.RMSE = do.call(cbind, List)
## Prepare boxplot
boxplot(Matrix.RMSE[,56], ylab = "RMSE", main = "RMSE BoxPlot (length of traning set = 65)")
## Variation of median RMSE
#install.packages("matrixStats")
library(matrixStats)
med = colMedians(Matrix.RMSE)
X = seq(10,65)
plot (med~X, type = "l", xlab = "length of training set", ylab = "median RMSE", main = "Variation of RMSE with length of training set")
# Load packages
library(ggplot2)
library(plyr)
library(gtable)
library(grid)
# Generate example data
dat <- data.frame(replicate(10, sample(1:5, 200, replace = TRUE)))
dat = dat[, 1:6]
dat <- as.data.frame(llply(dat, as.numeric))
dat <- cent
# Number of items, generate labels, and set size of text for correlations and item labels
n <- dim(dat)[2]
labels <- paste0("Item ", 1:n)
sizeItem = 16
sizeCor = 4
## List of scatterplots
scatter <- list()
for (i in 2:n) {
for (j in 1:(i-1)) {
# Data frame
df.point <- na.omit(data.frame(cbind(x = dat[ , j], y = dat[ , i])))
# Plot
p <- ggplot(df.point, aes(x, y)) +
geom_jitter(size = .7, position = position_jitter(width = .2, height= .2)) +
stat_smooth(method="lm", colour="black") +
theme_bw() + theme(panel.grid = element_blank())
name <- paste0("Item", j, i)
scatter[[name]] <- p
} }
## List of bar plots
bar <- list()
for(i in 1:n) {
# Data frame
bar.df <- as.data.frame(table(dat[ , i], useNA = "no"))
names(bar.df) <- c("x", "y")
# Plot
p <- ggplot(bar.df) +
geom_bar(aes(x = x, y = y), stat = "identity", width = 0.6) +
theme_bw() +  theme(panel.grid = element_blank()) +
ylim(0, max(bar.df$y*1.05))
name <- paste0("Item", i)
bar[[name]] <- p
}
## List of tiles
tile <- list()
for (i in 1:(n-1)) {
for (j in (i+1):n) {
# Data frame
df.point <- na.omit(data.frame(cbind(x = dat[ , j], y = dat[ , i])))
x = df.point[, 1]
y = df.point[, 2]
correlation = cor.test(x, y)
cor <- data.frame(estimate = correlation$estimate,
statistic = correlation$statistic,
p.value = correlation$p.value)
cor$cor = paste0("r = ", sprintf("%.2f", cor$estimate), "\n",
"t = ", sprintf("%.2f", cor$statistic), "\n",
"p = ", sprintf("%.3f", cor$p.value))
# Plot
p <- ggplot(cor, aes(x = 1, y = 1)) +
geom_tile(fill = "steelblue") +
geom_text(aes(x = 1, y = 1, label = cor),
colour = "White", size = sizeCor, show_guide = FALSE) +
theme_bw() + theme(panel.grid = element_blank())
name <- paste0("Item", j, i)
tile[[name]] <- p
} }
# Convert the ggplots to grobs,
# and select only the plot panels
barGrob <- llply(bar, ggplotGrob)
barGrob <- llply(barGrob, gtable_filter, "panel")
scatterGrob <- llply(scatter, ggplotGrob)
scatterGrob <- llply(scatterGrob, gtable_filter, "panel")
tileGrob <- llply(tile, ggplotGrob)
tileGrob <- llply(tileGrob, gtable_filter, "panel")
## Set up the gtable layout
gt <- gtable(unit(rep(1, n), "null"), unit(rep(1, n), "null"))
## Add the plots to the layout
# Bar plots along the diagonal
for(i in 1:n) {
gt <- gtable_add_grob(gt, barGrob[[i]], t=i, l=i)
}
# Scatterplots in the lower half
k <- 1
for (i in 2:n) {
for (j in 1:(i-1)) {
gt <- gtable_add_grob(gt, scatterGrob[[k]], t=i, l=j)
k <- k+1
} }
# Tiles in the upper half
k <- 1
for (i in 1:(n-1)) {
for (j in (i+1):n) {
gt <- gtable_add_grob(gt, tileGrob[[k]], t=i, l=j)
k <- k+1
} }
# Add item labels
gt <- gtable_add_cols(gt, unit(1.5, "lines"), 0)
gt <- gtable_add_rows(gt, unit(1.5, "lines"), 2*n)
for(i in 1:n) {
textGrob <- textGrob(labels[i], gp = gpar(fontsize = sizeItem))
gt <- gtable_add_grob(gt, textGrob, t=n+1, l=i+1)
}
for(i in 1:n) {
textGrob <- textGrob(labels[i], rot = 90, gp = gpar(fontsize = sizeItem))
gt <- gtable_add_grob(gt, textGrob, t=i, l=1)
}
# Add small gap between the panels
for(i in n:1) gt <- gtable_add_cols(gt, unit(0.2, "lines"), i)
for(i in (n-1):1) gt <- gtable_add_rows(gt, unit(0.2, "lines"), i)
# Add chart title
gt <- gtable_add_rows(gt, unit(1.5, "lines"), 0)
textGrob <- textGrob("Korrelationsmatrix", gp = gpar(fontface = "bold", fontsize = 16))
gt <- gtable_add_grob(gt, textGrob, t=1, l=3, r=2*n+1)
# Add margins to the whole plot
for(i in c(2*n+1, 0)) {
gt <- gtable_add_cols(gt, unit(.75, "lines"), i)
gt <- gtable_add_rows(gt, unit(.75, "lines"), i)
}
# Draw it
grid.newpage()
grid.draw(gt)
